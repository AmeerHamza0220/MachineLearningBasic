{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GObe36miZcfy"
   },
   "source": [
    "# Project: Online Shopper Intention Prediction using Machine Leaning\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9fH8AuPZcfz"
   },
   "source": [
    "## Loading in data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2Idbvn0lZcfz"
   },
   "outputs": [],
   "source": [
    "# importing python libiraries for project\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project has been implemented on AWS sagemaker studio lab so we don't need these lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "FPafyJWMTEGn",
    "outputId": "4f4b1816-cf4f-491b-ba57-d4a5a49b8275"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# File_copy = 'heart.csv'\n",
    "# import shutil\n",
    "# # shutil.copy('/content/drive/MyDrive/Python Projects/MS and PhD Semester Projects/MSCS-Advance Machine Learning Spring 2022/'+File_copy, \"/content/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "id": "KB2xU2Jbr4km",
    "outputId": "f4fe2363-3146-43fa-e75c-e49ab774c34e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.315166</td>\n",
       "      <td>80.818611</td>\n",
       "      <td>0.503569</td>\n",
       "      <td>34.472398</td>\n",
       "      <td>31.731468</td>\n",
       "      <td>1194.746220</td>\n",
       "      <td>0.022191</td>\n",
       "      <td>0.043073</td>\n",
       "      <td>5.889258</td>\n",
       "      <td>0.061427</td>\n",
       "      <td>2.124006</td>\n",
       "      <td>2.357097</td>\n",
       "      <td>3.147364</td>\n",
       "      <td>4.069586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.321784</td>\n",
       "      <td>176.779107</td>\n",
       "      <td>1.270156</td>\n",
       "      <td>140.749294</td>\n",
       "      <td>44.475503</td>\n",
       "      <td>1913.669288</td>\n",
       "      <td>0.048488</td>\n",
       "      <td>0.048597</td>\n",
       "      <td>18.568437</td>\n",
       "      <td>0.198917</td>\n",
       "      <td>0.911325</td>\n",
       "      <td>1.717277</td>\n",
       "      <td>2.401591</td>\n",
       "      <td>4.025169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>184.137500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>598.936905</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>0.025156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>93.256250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1464.157214</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>3398.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2549.375000</td>\n",
       "      <td>705.000000</td>\n",
       "      <td>63973.522230</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>361.763742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Administrative  Administrative_Duration  Informational  \\\n",
       "count    12330.000000             12330.000000   12330.000000   \n",
       "mean         2.315166                80.818611       0.503569   \n",
       "std          3.321784               176.779107       1.270156   \n",
       "min          0.000000                 0.000000       0.000000   \n",
       "25%          0.000000                 0.000000       0.000000   \n",
       "50%          1.000000                 7.500000       0.000000   \n",
       "75%          4.000000                93.256250       0.000000   \n",
       "max         27.000000              3398.750000      24.000000   \n",
       "\n",
       "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "count            12330.000000    12330.000000             12330.000000   \n",
       "mean                34.472398       31.731468              1194.746220   \n",
       "std                140.749294       44.475503              1913.669288   \n",
       "min                  0.000000        0.000000                 0.000000   \n",
       "25%                  0.000000        7.000000               184.137500   \n",
       "50%                  0.000000       18.000000               598.936905   \n",
       "75%                  0.000000       38.000000              1464.157214   \n",
       "max               2549.375000      705.000000             63973.522230   \n",
       "\n",
       "        BounceRates     ExitRates    PageValues    SpecialDay  \\\n",
       "count  12330.000000  12330.000000  12330.000000  12330.000000   \n",
       "mean       0.022191      0.043073      5.889258      0.061427   \n",
       "std        0.048488      0.048597     18.568437      0.198917   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.014286      0.000000      0.000000   \n",
       "50%        0.003112      0.025156      0.000000      0.000000   \n",
       "75%        0.016813      0.050000      0.000000      0.000000   \n",
       "max        0.200000      0.200000    361.763742      1.000000   \n",
       "\n",
       "       OperatingSystems       Browser        Region   TrafficType  \n",
       "count      12330.000000  12330.000000  12330.000000  12330.000000  \n",
       "mean           2.124006      2.357097      3.147364      4.069586  \n",
       "std            0.911325      1.717277      2.401591      4.025169  \n",
       "min            1.000000      1.000000      1.000000      1.000000  \n",
       "25%            2.000000      2.000000      1.000000      2.000000  \n",
       "50%            2.000000      2.000000      3.000000      2.000000  \n",
       "75%            3.000000      2.000000      4.000000      4.000000  \n",
       "max            8.000000     13.000000      9.000000     20.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Readining data from excel\n",
    "path='data/online_shoppers_intention.csv'\n",
    "data = pd.read_csv(path)\n",
    "data.dropna(inplace=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-5LCCSSwTE0",
    "outputId": "9bea7b31-6f3c-4522-ed8b-6ea00b5e74f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Administrative', 'Administrative_Duration', 'Informational',\n",
       "       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',\n",
       "       'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'Month',\n",
       "       'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType',\n",
       "       'Weekend', 'Revenue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8EhAG62RZWt"
   },
   "source": [
    "# Select Target and Input Variables/Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "GetD1mwBVPkX",
    "outputId": "1332f2fc-3166-4258-ff59-9c6e69e7608b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable ************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Revenue'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_target = 'Revenue'\n",
    "keys_features = ['Administrative', 'Administrative_Duration', 'Informational',\n",
    "       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',\n",
    "       'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'Month',\n",
    "       'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType',\n",
    "       'Weekend']\n",
    "\n",
    "\n",
    "print('Target Variable ************************')\n",
    "keys_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UK5f6rAKRHz-",
    "outputId": "7453d900-c11d-4d4a-ad06-40cd52200115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Features and Variables ************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Administrative',\n",
       " 'Administrative_Duration',\n",
       " 'Informational',\n",
       " 'Informational_Duration',\n",
       " 'ProductRelated',\n",
       " 'ProductRelated_Duration',\n",
       " 'BounceRates',\n",
       " 'ExitRates',\n",
       " 'PageValues',\n",
       " 'SpecialDay',\n",
       " 'Month',\n",
       " 'OperatingSystems',\n",
       " 'Browser',\n",
       " 'Region',\n",
       " 'TrafficType',\n",
       " 'VisitorType',\n",
       " 'Weekend']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Input Features and Variables ************************')\n",
    "keys_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2324085fa0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax=data[keys_target].value_counts().plot(kind='pie',autopct='%1.1f%%')\n",
    "ax.set_title(keys_target)\n",
    "#add legend \n",
    "labels=data[keys_target].value_counts().keys()\n",
    "ax.legend(labels,loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping 50% of rows with 'Revenue'==0 to make dataset less skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7119, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop(data[data['Revenue']==0].sample(frac=0.5,random_state=1).index)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable to hold summary of each classifier\n",
    "df_summary=pd.DataFrame(columns=['Algorithm','Accuracy','Precision','Recall','F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map objects dtype to int\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "        data[col] = LabelEncoder().fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SelectKBest to select top 12 features\n",
    "\n",
    "This method select features according to the k highest scores.\n",
    "For instance, we can perform a chi-square test to the samples to retrieve only the 12 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Administrative',\n",
       " 'Administrative_Duration',\n",
       " 'Informational',\n",
       " 'Informational_Duration',\n",
       " 'ProductRelated',\n",
       " 'ProductRelated_Duration',\n",
       " 'BounceRates',\n",
       " 'ExitRates',\n",
       " 'PageValues',\n",
       " 'SpecialDay',\n",
       " 'Month',\n",
       " 'VisitorType']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "selector = SelectKBest(chi2, k=12)\n",
    "selector.fit_transform(data[keys_features], data[keys_target])\n",
    "indices=selector.get_support(indices=True)\n",
    "\n",
    "top_12 = [keys_features[i] for i in indices]\n",
    "top_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ABiWSwVRM-o"
   },
   "source": [
    "# Train-Test Split (80% Training and 20% Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2G2crlDEFNmO"
   },
   "outputs": [],
   "source": [
    "Features = {'All Features  ': keys_features}\n",
    "Y = data[keys_target].copy()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "prob_test = 0.2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, Y, test_size=prob_test, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qR1D4EefSeUB"
   },
   "source": [
    "# User Defined Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_kiq4V-qXW5z"
   },
   "outputs": [],
   "source": [
    "# Train Test Data copy\n",
    "def select_X(keys):\n",
    "  X_train_A =  X_train[keys].copy()\n",
    "  X_test_A  =  X_test[keys].copy()\n",
    "  print(\"Train Samples = \", X_train_A.shape)\n",
    "  print(\"Test  Samples = \", X_test_A.shape)\n",
    "  return X_train_A, X_test_A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5NuJ8VWaY9jD"
   },
   "outputs": [],
   "source": [
    "# To compute Accuracy, precsion, recall, f1 score and confusion matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def compute_perf_metric(Yc_true,Yc_predict, Classifier, plot_results):\n",
    "  Results = {}\n",
    "  # accuracy: (tp + tn) / (p + n)\n",
    "  accuracy = np.round(accuracy_score(Yc_true,Yc_predict),3)\n",
    "  # precision tp / (tp + fp)\n",
    "  precision = np.round(precision_score(Yc_true,Yc_predict,average='macro'),3)\n",
    "  # recall: tp / (tp + fn)\n",
    "  recall = np.round(recall_score(Yc_true,Yc_predict,average='macro'),3)\n",
    "  # f1: 2 tp / (2 tp + fp + fn)\n",
    "  f1 = np.round(2*precision*recall/(precision+recall),3)\n",
    "  # confusion matrix\n",
    "  matrix = confusion_matrix(Yc_true,Yc_predict) \n",
    "  per_dict = {'Accuracy': accuracy, \n",
    "             'Precision': precision,\n",
    "             'Recall': recall,\n",
    "             'f1': f1,\n",
    "             'zConfusion_Matrix': matrix}\n",
    "  \n",
    "  if plot_results:\n",
    "    print('------'+ Classifier + '--------------')  \n",
    "    print('Accuracy:\\t', accuracy)\n",
    "    print('Precision:\\t', precision)\n",
    "    print('Recall: \\t', recall)\n",
    "    print('F1 score:\\t', f1)  \n",
    "    print('   ') \n",
    "    figure = plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(matrix, xticklabels = class_labels, annot=True,cmap=plt.cm.Blues,)\n",
    "    plt.tight_layout()\n",
    "    pos, textvals = plt.yticks()\n",
    "    plt.yticks(pos,class_labels, rotation=0,va=\"center\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "  return per_dict\n",
    "\n",
    "\n",
    "# To plot ROC curve method/study/classier wise on Test data\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "class_labels = np.unique(Y_train)\n",
    "Methods = [\"Naive Bayes\",\"Stochastic Gradient Descent\",\"Decision Tree\",\"Random Forest\",\"Gradient Boost\",\"Multilayer Perceptron\",\"Deep Neural Network\"]\n",
    "\n",
    "def plot_roc_curve_method_wise(y_scores,axs,TT):\n",
    "  fpr = dict()\n",
    "  tpr = dict()\n",
    "  roc_auc = dict()\n",
    "  for i in range(len(class_labels)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Yb_test[:, i], y_scores[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "  colors = cycle(['blue', 'red', 'green','yellow'])\n",
    "  for i, color in zip(range(len(class_labels)), colors):\n",
    "    axs.plot(fpr[i], tpr[i], color=color, lw=1.5,label='{0} Class (AUC = {1:0.2f})'''.format(class_names[i], roc_auc[i]))\n",
    "  axs.plot([0, 1], [0, 1], 'k--', lw=1.5)\n",
    "  axs.set_xlim([-0.05, 1.0])\n",
    "  axs.set_ylim([0.0, 1.05])\n",
    "  axs.set_xlabel('False Positive Rate')\n",
    "  axs.set_ylabel('True Positive Rate')\n",
    "  axs.set_title(\"ROC for \"+TT, fontsize=20)\n",
    "  axs.legend(loc=\"lower right\")\n",
    "  #axs.set_show()\n",
    "  return fpr, tpr, roc_auc \n",
    "\n",
    "  # To plot ROC for different classifiers predicted Class wise on Test data\n",
    "\n",
    "def plot_roc_curve_class_wise(fpr,tpr,roc_auc,axs,TT):  \n",
    "  colors = cycle(['blue', 'red', 'green','yellow','black','cyan','magenta'])\n",
    "  for i, color in zip(range(len(Methods)), colors):\n",
    "    axs.plot(fpr[i], tpr[i], color=color, lw=1.5,label='{0} (AUC = {1:0.2f})'''.format(Methods[i], roc_auc[i]))\n",
    "  axs.plot([0, 1], [0, 1], 'k--', lw=1.5)\n",
    "  axs.set_xlim([-0.05, 1.0])\n",
    "  axs.set_ylim([0.0, 1.05])\n",
    "  axs.set_xlabel('False Positive Rate')\n",
    "  axs.set_ylabel('True Positive Rate')\n",
    "  axs.set_title(\"ROC for \" + TT, fontsize=20)\n",
    "  axs.legend(loc=\"lower right\")\n",
    "  #axs.set_show()\n",
    "  return fpr, tpr, roc_auc \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76wwKGY4nXAZ"
   },
   "source": [
    "# SVM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-1yPYRcUo0-",
    "outputId": "5854be25-58e0-4d8d-c2cf-4687af9dde7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples =  (5695, 12)\n",
      "Test  Samples =  (1424, 12)\n",
      "  \n",
      "Results ======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Best Parameters  SVM': {'svc__kernel': 'rbf', 'svc__C': 1},\n",
       " 'Accuracy         SVM rbf': 0.865,\n",
       " 'Precision        SVM rbf': 0.846,\n",
       " 'Recall           SVM rbf': 0.801,\n",
       " 'F1 score         SVM rbf': 0.823,\n",
       " 'Confusion Matrix SVM rbf': array([975,  60, 132, 257])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#randomized search for SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "X_train_A, X_test_A = select_X(keys=top_12)\n",
    "SVMClass = make_pipeline(StandardScaler(), SVC())\n",
    "params={'svc__C': [1, 10, 100], 'svc__kernel': ['linear', 'rbf']}\n",
    "random_search = RandomizedSearchCV(SVMClass, param_distributions=params, n_iter=4, cv=5, verbose=0, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train_A, Y_train)\n",
    "kernel= random_search.best_params_['svc__kernel']\n",
    "\n",
    "P = compute_perf_metric(Yc_true=Y_test,Yc_predict=random_search.predict(X_test_A), Classifier = 'SVM {}'.format(kernel), plot_results = False)   \n",
    "Results = {}\n",
    "Results[\"Best Parameters  SVM\"] = random_search.best_params_\n",
    "Results[\"Accuracy         SVM {}\".format(kernel)] = P['Accuracy']\n",
    "Results[\"Precision        SVM {}\".format(kernel)] = P['Precision']\n",
    "Results[\"Recall           SVM {}\".format(kernel)] = P['Recall']\n",
    "Results[\"F1 score         SVM {}\".format(kernel)] = P['f1']\n",
    "Results[\"Confusion Matrix SVM {}\".format(kernel)] = P['zConfusion_Matrix'].ravel()\n",
    "df_summary.loc[len(df_summary)] = ['SVM',P['Accuracy'],P['Precision'],P['Recall'],P['f1']]\n",
    "\n",
    "\n",
    "print(\"  \")\n",
    "print(\"Results ======================================\")\n",
    "Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JXjymeongj0"
   },
   "source": [
    "# Logestic Regression Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYCLsdYJVnCx",
    "outputId": "c83e20ca-4a09-4e26-cb8f-cb173e74c640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples =  (5695, 12)\n",
      "Test  Samples =  (1424, 12)\n",
      "  \n",
      "Results ======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Best Parameters  Logestic Regression': {'logisticregression__solver': 'liblinear',\n",
       "  'logisticregression__C': 100},\n",
       " 'Accuracy         Logestic Regression': 0.847,\n",
       " 'Precision        Logestic Regression': 0.851,\n",
       " 'Recall           Logestic Regression': 0.747,\n",
       " 'F1 score         Logestic Regression': 0.796,\n",
       " 'Confusion Matrix Logestic Regression': array([1001,   34,  184,  205])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "#randomized search for SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "X_train_A, X_test_A = select_X(keys=top_12)\n",
    "LRClass = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "params={'logisticregression__C': [0.1, 1, 10, 100], 'logisticregression__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "random_search_lr = RandomizedSearchCV(LRClass, param_distributions=params, n_iter=10, cv=5, verbose=0, random_state=42, n_jobs=-1)\n",
    "random_search_lr.fit(X_train_A, Y_train)\n",
    "# LRClass.fit(X_train_A, Y_train.ravel())\\\n",
    "joblib.dump(random_search_lr, 'filename.pkl') \n",
    "P = compute_perf_metric(Yc_true=Y_test,Yc_predict=random_search_lr.predict(X_test_A), Classifier = 'LR', plot_results = False)\n",
    "Results = {}\n",
    "Results[\"Best Parameters  Logestic Regression\"] = random_search_lr.best_params_\n",
    "Results[\"Accuracy         Logestic Regression\"] = P['Accuracy']\n",
    "Results[\"Precision        Logestic Regression\"] = P['Precision']\n",
    "Results[\"Recall           Logestic Regression\"] = P['Recall']\n",
    "Results[\"F1 score         Logestic Regression\"] = P['f1']\n",
    "Results[\"Confusion Matrix Logestic Regression\"] = P['zConfusion_Matrix'].ravel()\n",
    "df_summary.loc[len(df_summary)] = ['Logestic Regression',P['Accuracy'],P['Precision'],P['Recall'],P['f1']]\n",
    "\n",
    "print(\"  \")\n",
    "print(\"Results ======================================\")\n",
    "Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJ5_SHqpqsUw"
   },
   "source": [
    "# Decision Tree Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "msq8b-UtInWT",
    "outputId": "845d1c97-efe7-482a-a206-b92aae6a0c74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples =  (5695, 12)\n",
      "Test  Samples =  (1424, 12)\n",
      "  \n",
      "Results ======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Best Parameters  Decision Tree': {'decisiontreeclassifier__min_samples_split': 2,\n",
       "  'decisiontreeclassifier__min_samples_leaf': 2,\n",
       "  'decisiontreeclassifier__max_depth': 2,\n",
       "  'decisiontreeclassifier__criterion': 'gini'},\n",
       " 'Accuracy         Decision Tree ': 0.863,\n",
       " 'Precision        Decision Tree ': 0.825,\n",
       " 'Recall           Decision Tree ': 0.838,\n",
       " 'F1 score         Decision Tree ': 0.831,\n",
       " 'Confusion Matrix Decision Tree ': array([925, 110,  85, 304])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importinig libiaries for Dicision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train_A, X_test_A = select_X(keys=top_12)\n",
    "DTClass = make_pipeline(StandardScaler(), DecisionTreeClassifier())\n",
    "params={'decisiontreeclassifier__max_depth': [2,5,10,25,50],\n",
    "        'decisiontreeclassifier__min_samples_leaf': [2,5,10],\n",
    "        'decisiontreeclassifier__min_samples_split': [2,5,10],\n",
    "        'decisiontreeclassifier__criterion': ['gini', 'entropy']}\n",
    "\n",
    "random_search_dt = RandomizedSearchCV(DTClass, param_distributions=params, n_iter=10, cv=5, verbose=0, random_state=42, n_jobs=-1)\n",
    "random_search_dt.fit(X_train_A, Y_train)\n",
    "# DTClass.fit(X_train_A, Y_train.ravel())\n",
    "P = compute_perf_metric(Yc_true=Y_test,Yc_predict=random_search_dt.predict(X_test_A), Classifier = 'DT', plot_results = False)\n",
    "Results = {}\n",
    "Results[\"Best Parameters  Decision Tree\"] = random_search_dt.best_params_\n",
    "Results[\"Accuracy         Decision Tree \"] = P['Accuracy']\n",
    "Results[\"Precision        Decision Tree \"] = P['Precision']\n",
    "Results[\"Recall           Decision Tree \"] = P['Recall']\n",
    "Results[\"F1 score         Decision Tree \"] = P['f1']\n",
    "Results[\"Confusion Matrix Decision Tree \"] = P['zConfusion_Matrix'].ravel()\n",
    "df_summary.loc[len(df_summary)] = ['Decision Tree',P['Accuracy'],P['Precision'],P['Recall'],P['f1']]\n",
    "\n",
    "print(\"  \")\n",
    "print(\"Results ======================================\")\n",
    "Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBidYmBoXwRS"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pgHwtwuaXyX8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples =  (5695, 12)\n",
      "Test  Samples =  (1424, 12)\n",
      "  \n",
      "Results ======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Best Parameters  Random Forest': {'randomforestclassifier__n_estimators': 100,\n",
       "  'randomforestclassifier__min_samples_split': 2,\n",
       "  'randomforestclassifier__min_samples_leaf': 5,\n",
       "  'randomforestclassifier__criterion': 'gini'},\n",
       " 'Accuracy         Random Forest ': 0.866,\n",
       " 'Precision        Random Forest ': 0.838,\n",
       " 'Recall           Random Forest ': 0.815,\n",
       " 'F1 score         Random Forest ': 0.826,\n",
       " 'Confusion Matrix Random Forest ': array([959,  76, 115, 274])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write ur RF code here\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train_A, X_test_A = select_X(keys=top_12)\n",
    "RFClass = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100, min_samples_leaf = 5))\n",
    "params={'randomforestclassifier__n_estimators': [100, 200, 300,500], 'randomforestclassifier__min_samples_leaf': [2,5,10], 'randomforestclassifier__min_samples_split': [2,5,10], 'randomforestclassifier__criterion': ['gini', 'entropy'],\n",
    "       }\n",
    "random_search_rf = RandomizedSearchCV(RFClass, param_distributions=params, n_iter=10, cv=5, verbose=0, random_state=42, n_jobs=-1)\n",
    "random_search_rf.fit(X_train_A, Y_train)\n",
    "# RFClass.fit(X_train_A, Y_train.ravel())\n",
    "P = compute_perf_metric(Yc_true=Y_test,Yc_predict=random_search_rf.predict(X_test_A), Classifier = 'RF', plot_results = False)\n",
    "Results = {}\n",
    "Results[\"Best Parameters  Random Forest\"] = random_search_rf.best_params_\n",
    "Results[\"Accuracy         Random Forest \"] = P['Accuracy']\n",
    "Results[\"Precision        Random Forest \"] = P['Precision']\n",
    "Results[\"Recall           Random Forest \"] = P['Recall']\n",
    "Results[\"F1 score         Random Forest \"] = P['f1']\n",
    "Results[\"Confusion Matrix Random Forest \"] = P['zConfusion_Matrix'].ravel()\n",
    "df_summary.loc[len(df_summary)] = ['Random Forest',P['Accuracy'],P['Precision'],P['Recall'],P['f1']]\n",
    "\n",
    "print(\"  \")\n",
    "print(\"Results ======================================\")\n",
    "Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EEcRd_Bv3yt"
   },
   "source": [
    "# DNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FZZX-khhww7F"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "def build_and_compile_model(norm, hidden_layers, neurons):\n",
    "  model = keras.Sequential(norm)\n",
    "  for L in range(hidden_layers):\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile('adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "def plot_loss(history, x_label, y_label):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.ylim([0, 10])\n",
    "  plt.xlabel(x_label)\n",
    "  plt.ylabel(y_label)\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  \n",
    "#callbacks\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "callbacks=[early_stop, reduce_lr]\n",
    "\n",
    "def dnn_ss(hidden_layers,neurons,X_Train, Y_Train, X_Test, Y_Test, classes, target):\n",
    "  X_train_norm = preprocessing.Normalization(axis=-1)\n",
    "  X_train_norm.adapt(np.array(X_Train))\n",
    "  model = build_and_compile_model(X_train_norm, hidden_layers=hidden_layers, neurons=neurons)\n",
    "  #dnn_inflation_model.summary()\n",
    "\n",
    "  history = model.fit(X_Train, Y_Train, batch_size=32,validation_split=0.2, verbose=0, epochs=100, callbacks=callbacks)\n",
    "  #plot_loss(history_inflation, x_label = 'Epochs', y_label = 'Inflation Loss')  \n",
    "  Yp = (model.predict(X_Test) > 0.499).astype(int)\n",
    "  P =compute_perf_metric(Yc_true=Y_Test,Yc_predict=Yp, Classifier = 'DNN {}-{}'.format(hidden_layers,neurons), plot_results = False)\n",
    "  return P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3emRmjhewRqs",
    "outputId": "e088ed75-e410-4a49-be39-2c07cdfeb4db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples =  (5695, 12)\n",
      "Test  Samples =  (1424, 12)\n",
      "45/45 [==============================] - 0s 1ms/step\n",
      "Layers = 5,\t Neurons = 100,\t Accuracy = 0.861,\t Precision = 0.836,\t Recall = 0.802,\t F1 = 0.819\n",
      "  \n",
      "Results ======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy         ANN 5-100 ': 0.861,\n",
       " 'Precision        ANN 5-100 ': 0.836,\n",
       " 'Recall           ANN 5-100 ': 0.802,\n",
       " 'F1 score         ANN 5-100 ': 0.819,\n",
       " 'Confusion Matrix ANN 5-100 ': array([261, 128,  70, 965])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 5\n",
    "N = 100\n",
    "\n",
    "target_class = Y.unique()[0]\n",
    "\n",
    "X_train_A, X_test_A = select_X(keys=top_12)\n",
    "P = dnn_ss(hidden_layers=L,neurons = N,X_Train= X_train_A, Y_Train= (Y_train.ravel()==target_class).astype(int),X_Test = X_test_A,  Y_Test = (Y_test.ravel()==target_class).astype(int), classes = Y_test.unique(), target = target_class)\n",
    "Results = {}\n",
    "Results[\"Accuracy         ANN {}-{} \".format(L,N)] = P['Accuracy']\n",
    "Results[\"Precision        ANN {}-{} \".format(L,N)] = P['Precision']\n",
    "Results[\"Recall           ANN {}-{} \".format(L,N)] = P['Recall']\n",
    "Results[\"F1 score         ANN {}-{} \".format(L,N)] = P['f1']\n",
    "Results[\"Confusion Matrix ANN {}-{} \".format(L,N)] = P['zConfusion_Matrix'].ravel()    \n",
    "print(\"Layers = {},\\t Neurons = {},\\t Accuracy = {},\\t Precision = {},\\t Recall = {},\\t F1 = {}\".format(L,N,P['Accuracy'], P['Precision'],P['Recall'], P['f1']) )\n",
    "df_summary.loc[len(df_summary)] = ['ANN',P['Accuracy'],P['Precision'],P['Recall'],P['f1']]\n",
    "\n",
    "\n",
    "\n",
    "print(\"  \")\n",
    "print(\"Results ======================================\")\n",
    "Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 more techniques to implement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples =  (5695, 12)\n",
      "Test  Samples =  (1424, 12)\n",
      "  \n",
      "Results ======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Best Parameters  Naive Bayes': {'gaussiannb__var_smoothing': 1},\n",
       " 'Accuracy         Naive Bayes ': 0.784,\n",
       " 'Precision        Naive Bayes ': 0.737,\n",
       " 'Recall           Naive Bayes ': 0.67,\n",
       " 'F1 score         Naive Bayes ': 0.702,\n",
       " 'Confusion Matrix Naive Bayes ': array([953,  82, 226, 163])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X_train_A, X_test_A = select_X(keys=top_12)\n",
    "NBClass = make_pipeline(StandardScaler(), GaussianNB())\n",
    "params={'gaussiannb__var_smoothing': [0.1, 1, 10, 100, 1000]}\n",
    "random_search_nb = RandomizedSearchCV(NBClass, param_distributions=params, n_iter=5, cv=5, verbose=0, random_state=42, n_jobs=-1)\n",
    "random_search_nb.fit(X_train_A, Y_train)\n",
    "# NBClass.fit(X_train_A, Y_train.ravel())\n",
    "P = compute_perf_metric(Yc_true=Y_test,Yc_predict=random_search_nb.predict(X_test_A), Classifier = 'NB', plot_results = False)\n",
    "Results = {}\n",
    "Results['Best Parameters  Naive Bayes'] = random_search_nb.best_params_\n",
    "Results[\"Accuracy         Naive Bayes \"] = P['Accuracy']\n",
    "Results[\"Precision        Naive Bayes \"] = P['Precision']\n",
    "Results[\"Recall           Naive Bayes \"] = P['Recall']\n",
    "Results[\"F1 score         Naive Bayes \"] = P['f1']\n",
    "Results[\"Confusion Matrix Naive Bayes \"] = P['zConfusion_Matrix'].ravel()\n",
    "df_summary.loc[len(df_summary)] = ['Naive Bayes',P['Accuracy'],P['Precision'],P['Recall'],P['f1']]\n",
    "\n",
    "print(\"  \")\n",
    "print(\"Results ======================================\")\n",
    "Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost library provides a fast implementation of gradient boosted trees that can run on GPU as compare to sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples =  (5695, 12)\n",
      "Test  Samples =  (1424, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/stat/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "Results ======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Best Parameters  XGBoost': {'xgboostclassifier__n_estimators': 900,\n",
       "  'xgboostclassifier__max_depth': 900,\n",
       "  'xgboostclassifier__learning_rate': 0.1},\n",
       " 'Accuracy         XGBoost ': 0.864,\n",
       " 'Precision        XGBoost ': 0.837,\n",
       " 'Recall           XGBoost ': 0.812,\n",
       " 'F1 score         XGBoost ': 0.824,\n",
       " 'Confusion Matrix XGBoost ': array([960,  75, 118, 271])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xgbclassifier\n",
    "from xgboost import XGBClassifier\n",
    "X_train_A, X_test_A = select_X(keys=top_12)\n",
    "XGBClassifier = XGBClassifier(tree_method='gpu_hist',verbosity = 0)\n",
    "params={'xgboostclassifier__n_estimators': [100, 500, 900, 1000,5000], \n",
    "'xgboostclassifier__learning_rate':[0.01, 0.1],\n",
    "'xgboostclassifier__max_depth': [10,100,900]}\n",
    "random_search_xgb = RandomizedSearchCV(XGBClassifier, param_distributions=params, n_iter=10, cv=5, verbose=0, random_state=42, n_jobs=-1)\n",
    "random_search_xgb.fit(X_train_A, Y_train)\n",
    "# XGBClassifier.fit(X_train_A, Y_train.ravel())\n",
    "P = compute_perf_metric(Yc_true=Y_test,Yc_predict=random_search_xgb.predict(X_test_A), Classifier = 'XGB', plot_results = False)\n",
    "Results = {}\n",
    "Results[\"Best Parameters  XGBoost\"] = random_search_xgb.best_params_\n",
    "Results[\"Accuracy         XGBoost \"] = P['Accuracy']\n",
    "Results[\"Precision        XGBoost \"] = P['Precision']\n",
    "Results[\"Recall           XGBoost \"] = P['Recall']\n",
    "Results[\"F1 score         XGBoost \"] = P['f1']\n",
    "Results[\"Confusion Matrix XGBoost \"] = P['zConfusion_Matrix'].ravel()\n",
    "df_summary.loc[len(df_summary)] = ['XGBoost',P['Accuracy'],P['Precision'],P['Recall'],P['f1']]\n",
    "\n",
    "print(\"  \")\n",
    "print(\"Results ======================================\")\n",
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logestic Regression</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm  Accuracy  Precision  Recall     F1\n",
       "0                  SVM     0.865      0.846   0.801  0.823\n",
       "1  Logestic Regression     0.847      0.851   0.747  0.796\n",
       "2        Decision Tree     0.863      0.825   0.838  0.831\n",
       "3        Random Forest     0.866      0.838   0.815  0.826\n",
       "4                  ANN     0.861      0.836   0.802  0.819\n",
       "5          Naive Bayes     0.784      0.737   0.670  0.702\n",
       "6              XGBoost     0.864      0.837   0.812  0.824"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MSCS_Project_Spring_2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "stat:Python",
   "language": "python",
   "name": "conda-env-stat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f946df053fbf2b937619d3c5458e7af74262f9a954d8797ba0b27400bcafe06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
