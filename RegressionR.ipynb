{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled20.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPsCm+ytFYOiCO+pumYLNLi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmeerHamza0220/MachineLearningBasic/blob/main/RegressionR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some notes**"
      ],
      "metadata": {
        "id": "qn8PmZ1WwbD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some latex that will be helpful through notes** \n",
        "\n",
        "\n",
        "$2^2+2^2=8$\n",
        "\n",
        "$ \\cos^2 \\theta +\\sin^2\\theta=1$\n",
        "\n",
        "$2 \\times 2=4$\n",
        "\n",
        "$\\sqrt[4]{333}$\n",
        "\n",
        "**fractions**\n",
        "\n",
        "$\\frac{2}{3}$\n",
        "\n",
        "$\\frac{\\sqrt{x+3}}{x+2}$\n",
        "\n",
        "**Brackets**\n",
        "\n",
        "$ \\bigg[ \\Big\\{ \\big(3+2\\big) / 5 \\Big\\} \\times 6 \\bigg] $\n",
        "\n",
        "**Summations**\n",
        "\n",
        "$\\sum_{i=0}^{b}g(i)=0$\n",
        "\n",
        "**Integration**\n",
        "\n",
        "$\\int_{0}^{\\infty} f(x)$\n",
        "\n",
        "**limit**\n",
        "\n",
        "$\\lim_{x \\to c} f(x)$"
      ],
      "metadata": {
        "id": "YRu0HP3qykuU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "He we have some concepts to \n",
        "remember before lab\n"
      ],
      "metadata": {
        "id": "1ifdSr_ywfLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assessing the Accuracy of the Coefficient Estimates**\n",
        "\n",
        "If we use the bias sample mean ˆμ to estimate μ, this estimate is unbiased, in the sense that unbiased\n",
        "on average, we expect ˆμ to equal μ.\n",
        "\n",
        "How far off will that single estimate of ˆμ be? In general, we answer this question by computing the standard error of ˆμ, written as SE(ˆμ). We have\n",
        "the well-known formula\n",
        "\n",
        "**Var(ˆμ)= SE(ˆμ)2 = $\\frac{σ^2}{n}$\n",
        "\n",
        "Roughly speaking, the standard error tells us the average amount that this estimate ˆμ differs from the actual value of μ"
      ],
      "metadata": {
        "id": "QB7rt4YsxnAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a similar vein, we can wonder how close\n",
        "βˆ0\n",
        "and ˆβ1 are to the true values β0 and β1. To compute the standard errors associated with ˆβ0 and ˆβ1, we use the following formulas\n",
        "\n",
        "$SE(β_0)^2 =σ^2 \\bigg[ \\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^{n} (x_i-\\bar{x})} \\bigg]$ \n",
        " $SE(β_1)^2 =\\frac{σ^2}{\\sum_{i=1}^{n} (x_i-\\bar{x})}  $\n",
        "\n",
        "> Where $σ^2 =var(ϵ)$\n",
        "\n",
        "**Confidence Interval**\n",
        "\n",
        "Standard errors can be used to compute confidence intervals.\n",
        "A 95%\n",
        "confidence interval is defined as a range of values such that with 95% probability, the range will contain the true unknown value of the parameter\n",
        "\n",
        "**hypothesis testing**\n",
        "\n",
        "Standard errors can also be used to perform hypothesis tests on the\n",
        "coefficients\n",
        "\n",
        "To test the null hypothesis, we need to determine whether\n",
        "$\\bar{β_1}$, our estimate for $β_1$, is sufficiently far from zero that we can\n",
        "be confident that $β_1$ is non-zero.How far is far enough. This depend on standard error\n",
        "\n",
        "In practice, we compute a t-statistic, t-statistic given by\n",
        "\n",
        "$t=\\frac{\\bar{β_1-0}}{SE(\\bar{β_1})}$\n",
        "\n",
        "which measures the number of standard deviations that ˆβ1 is away from 0. If there really is no relationship between X and Y, then we expect that (3.14) will have a t-distribution with n−2 degrees of freedom\n",
        "\n",
        "it is a simple matter to compute the probability of observing any number equal to |t| or larger in absolute value, assuming β1 = 0. We call this probability the p-value. Roughly speaking, we interpret the p-value as follows: a small\n",
        "p-value indicates that it is unlikely to observe such a substantial association between the predictor and the response due to chance, in the absence of any real association between the predictor and the response. Hence, if we\n",
        "see a small p-value, then we can infer that there is an association between the predictor and the response. We reject the null hypothesis—that is, we declare a relationship to exist between X and Y"
      ],
      "metadata": {
        "id": "GL0VMe32x03o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assessing the Accuracy of the Model**\n",
        "\n",
        "The quality of a linear regression fit is typically assessed using two related quantities: the residual standard error (RSE) and the R2\n",
        "\n",
        "The RSE is an estimate of the standard deviation of ϵ. Roughly speaking, it is the average amount that the response will deviate from the true regression line. It is computed using the formula\n",
        "RSE=$\\sqrt{\\frac{1}{n-2}RSS}$\n",
        "The RSE is considered a measure of the lack of fit of the model  to\n",
        "the data. If the predictions obtained using the model are very close to the true outcome values\n",
        "\n",
        "**$R^2$ statistics**\n",
        "The RSE provides an absolute measure of lack of fit of the model (3.5) to the data. But since it is measured in the units of Y, it is not always clear what constitutes a good RSE. The R2 statistic provides an alternative measure of fit. It takes the form of a proportion—the proportion of variance\n",
        "\n",
        "so it always takes on a value between 0 and 1, and is independent of the scale of Y.\n",
        "\n",
        "$R^2=\\frac{TSS-RSS}{TSS}$\n",
        "\n",
        "TSS measures the total variance in the response Y, and can be thought of as the amount of variability inherent in the response before the regression is performed. In contrast, RSS measures the amount of variability that is left unexplained after performing the regression. Hence, TSS−RSS measures the amount of variability in the response that is explained (or removed) by performing the regression, and R2 measures the proportion of variability in Y that can be explained using X. An R2 statistic that is close to 1 indicates that a large proportion of the variability in the response is explained by the regression. A number near 0 indicates that the regression does not explain much of the variability in the response"
      ],
      "metadata": {
        "id": "iWcmdOwtfv6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <b>Multiple Linear Regression</b>\n",
        "</center>\n",
        "\n",
        "Some Important Questions\n",
        "\n",
        "1. Is at least one of the predictors X1,X2,. ..,Xp useful in predicting the response?\n",
        "2. Do all the predictors help to explain Y, or is only a subset of the predictors useful?\n",
        "3. How well does the model fit the data?\n",
        "4. Given a set ofpredictor values, what response value should we predict, and how accurate is our prediction?\n",
        "\n",
        "<b> One: Is There a Relationship Between the Response and Predictors?</b>\n",
        "\n",
        "The hypothesis test is performed by computing the F-statistic\n",
        "<center>$F=\\frac{(TSS-RSS)/p}{RSS/(n-p-1)}$</center>\n",
        "Hence, when there is no relationship between the response and predictors, one would expect the F-statistic to take on a value close to 1.\n",
        "On the other hand, if $H_a$ (alternative hypothesis) is true, then E{(TSS − RSS)/p} > σ2, so we expect F to be greater than 1.\n",
        "In other words, the large F-statistic suggests that at least one of the advertising media must be related to sales. \n",
        "How large does the F-statistic need to be before we can reject H0 and conclude that there is a relationship? the answer depends on the values of n and p.\n",
        "For any given value of n and p, any statistical software package can be used to compute the p-value associated with the F-statistic using this distribution. Based on this p-value, we can determine whether or not to reject $H_0$\n",
        "\n",
        "<b>Two: Deciding on Important Variables</b>\n",
        "\n",
        "If we conclude on the basis of that p-value that at least one of the predictors is related to the response, then it is natural to wonder which are the guilty ones! We could look at the individual p-values as in Table 3.4, but as discussed (and as further explored in Chapter 13), if p is large we are likely to make some false discoveries\n",
        "\n",
        "There are other methods which will be covered in chapter 6\n",
        "\n",
        "<b>Three: Model Fit</b>\n",
        "Two of the most common numerical measures of model fit are the RSE and R2, the fraction of variance explained. These quantities are computed and interpreted in the same fashion as for simple linear regression. Almost same as before.\n",
        "\n",
        "<b>Four: Predictions</b>\n",
        "\n",
        "given that $100,000 is spent on TV advertising and $20,000 is spent on radio advertising in each city, the 95% confidence interval is [10,985, 11,528]. We interpret this to mean that 95% of intervals of this form will contain the true value of f(X)\n",
        "\n",
        "<center><b>Other Considerations in the Regression Model</b></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "af3x0jVIv7Vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use interaction term and non linear term to extend our linear model.\n",
        "\n",
        "<b>Potential Problems\n",
        "</b>\n",
        "<ol>\n",
        "<li> Non-linearity of the response-predictor relationships.\n",
        "<li> Correlation of error terms.</li>\n",
        " <li> Non-constant variance of error terms. </li>\n",
        "<li> Outliers. </li>\n",
        "<li> High-leverage points.</li>\n",
        "<li> Collinearity.</li>\n",
        "</ol>\n",
        "\n",
        "<b>1. Non-linearity of the Data</b>\n",
        "\n",
        "Residual plots are a useful graphical tool for identifying non-linearity.\n",
        "Given a simple linear regression model, we can plot the residuals, ei = yi − ˆyi, versus the predictor xi/\n",
        "Ideally, the residual plot will show no\n",
        "discernible pattern. The presence of a pattern may indicate a problem with some aspect of the linear model.\n",
        "The residuals exhibit a clear U-shape, which provides a strong indication of non-linearity in the data.\n",
        "\n",
        "<b>2. Correlation of Error Terms</b>\n",
        "An important assumption of the linear regression model is that the error terms, ϵ1, ϵ2,. .., ϵn, are uncorrelated. What does this mean? For instance, if the errors are uncorrelated, then the fact that ϵi is positive provides little or no information about the sign of ϵi+1. The standard errors that are computed for the estimated regression coefficients or the fitted values are based on the assumption of uncorrelated error terms. If in fact there is correlation among the error terms, then the estimated standard errors will tend to underestimate the true standard errors. As a result, confidence and prediction intervals will be narrower than they should be.\n",
        "\n",
        "Such correlations frequently occur in the context of time series data.\n",
        "In order to determine if this is the case for a given data set, we can plot the residuals from our model as a function of time. If the errors are uncorrelated, then there should be no discernible pattern. On the other hand, if the error terms are positively correlated, then we may see tracking in the residuals—that is, adjacent residuals may have\n",
        "similar values. \n",
        "\n",
        "<b>3. Non-constant Variance of Error Terms</b>\n",
        "Another important assumption of the linear regression model is that the error terms have a constant variance, Var(ϵi)= σ2. The standard errors, confidence intervals, and hypothesis tests associated with the linear model rely upon this assumption. Unfortunately, it is often the case that the variances of the error terms are non-constant. \n",
        "One can identify non-constant variances in the errors, or heteroscedasticity, from the presence of a funnel shape in\n",
        "the residual plot. \n",
        "When faced with this problem, one possible solution is to transform the response Y using a concave function such as log Y or\n",
        "√ Y. Such\n",
        "a transformation results in a greater amount of shrinkage of the larger responses, leading to a reduction in heteroscedasticity.\n",
        "\n",
        "<b>4. Outliers</b>\n",
        "Outliers usually have no effect on least square fit. However they cause other problem with interpretation.\n",
        "For instance, in this example, the RSE is 1.09 when the outlier is included in the regression, but it is only 0.77 when the outlier is removed. Since the RSE is used to compute all confidence intervals and p-values, such a dramatic increase caused by a single data point can have implications for the interpretation of the fit.\n",
        "\n",
        "Residual plots can be used to identify outliers.\n",
        "it can be difficult to decide how large a residual needs to be before we consider the point to be an outlier. To address this problem, instead of plotting the residuals, we can plot the studentized residuals, computed by dividing each residual ei by its estimated standard\n",
        "error. Observations whose studentized residuals are greater than 3 in absolute value are possible outliers.\n",
        "We can remove outlier if we believe it was included by error in measurement\n",
        "\n",
        "<b>5. High Leverage Points</b>\n",
        "An outlier is a data point whose response y does not follow the general trend of the rest of the data.\n",
        "A data point has high leverage if it has \"extreme\" predictor x values. With a single predictor, an extreme x value is simply one that is particularly high or low\n",
        "In order to quantify an observation’s leverage, we compute the leverage statistic. A large value of this statistic indicates an observation with high\n",
        "leverage. For a simple linear regression,\n",
        "<br>\n",
        "$h_i=\\frac{1}{n}+\\frac{(x_i-\\bar{x})}{\\sum{i=1}{n}(x_i-\\bar{x})^2}$\n",
        "\n",
        "<b>6. Collinearity</b>\n",
        "Collinearity refers to the situation in which two or more predictor variables\n",
        "are closely related to one another.\n",
        "The presence of collinearity can pose problems in the regression context, since it can be difficult to separate out the individual effects of collinear variables on the response. In other words, since limit and rating tend to increase or decrease together, it can be difficult to determine how each one separately is associated with the response,\n",
        "Since collinearity reduces the accuracy of the estimates of the regression coefficients, it causes the standard error for βˆj to grow. Recall that the\n",
        "t-statistic for each predictor is calculated by dividing βˆj by its standard\n",
        "error. Consequently, collinearity results in a decline in the t-statistic. As a result, in the presence of collinearity, we may fail to reject null hypotheisis.<br>\n",
        "A simple way to detect collinearity is to look at the correlation matrix\n",
        "of the predictors.\n",
        "An element of this matrix that is large in absolute value indicates a pair of highly correlated variables, and therefore a collinearity problem in the data. Unfortunately, not all collinearity problems can be detected by inspection of the correlation matrix: it is possible for collinearity to exist between three or more variables even if no pair of variables has a particularly high correlation. We call this situation multicollinearity.\n",
        "Instead of inspecting the correlation matrix, a better way to assess multicollinearity is to compute the variance inflation factor (VIF). The VIF is\n",
        "the ratio of the variance of ˆβj when fitting the full model divided by the variance of ˆβj if fit on its own. The smallest possible value for VIF is 1, which indicates the complete absence of collinearity. Typically in practice there is a small amount of collinearity among the predictors. As a rule of thumb, a VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity.\n",
        "When faced with the problem of collinearity, there are two simple solutions. The first is to drop one of the problematic variables from the regression. This can usually be done without much compromise to the regression fit, since the presence of collinearity implies that the information that this variable provides about the response is redundant in the presence of the other variables"
      ],
      "metadata": {
        "id": "XQXgLYnqgT17"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVBkTNlhrRpG"
      },
      "outputs": [],
      "source": [
        "library (MASS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages('ISLR')\n",
        "library (ISLR)"
      ],
      "metadata": {
        "id": "tPMZOrNjrW1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names(Boston)"
      ],
      "metadata": {
        "id": "UEs-5EdarjL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attach (Boston)\n",
        "lm.fit =lm(medv ~ lstat)"
      ],
      "metadata": {
        "id": "RQ2HhplgsqsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm.fit"
      ],
      "metadata": {
        "id": "6hCoavfot_Rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(lm.fit)"
      ],
      "metadata": {
        "id": "s-4VyrRKuF7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names(lm.fit )"
      ],
      "metadata": {
        "id": "Z7OT1x1GuPf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confint(lm.fit)"
      ],
      "metadata": {
        "id": "u_DJWqI2uZea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g1ukqjd9r_SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(lm.fit,data.frame(lstat=c(5,10,15)),interval='confidence')"
      ],
      "metadata": {
        "id": "BKZgtxJsu2Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(lm.fit,data.frame(lstat=c(5,10,15)),interval='prediction')"
      ],
      "metadata": {
        "id": "Rxc4aC_RvQOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(lstat,medv)\n",
        "abline(lm.fit,col='red',lwd=3)"
      ],
      "metadata": {
        "id": "LOO9PSaIvbxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(lm.fit)"
      ],
      "metadata": {
        "id": "EYny-VpPwD6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiple Regression**"
      ],
      "metadata": {
        "id": "ZZKKg0Q85-id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm.fit=lm(medv~lstat+age,data=Boston)\n",
        "summary(lm.fit)"
      ],
      "metadata": {
        "id": "fBqBVtd9597r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# on all variable\n",
        "lm.fit=lm(medv~.,data=Boston)\n",
        "summary(lm.fit)"
      ],
      "metadata": {
        "id": "xV5fEdrP6w2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#age has high p value so exclude\n",
        "lm.fit=lm(medv~.-age,data=Boston)\n",
        "summary(lm.fit)"
      ],
      "metadata": {
        "id": "3BmGVUW87fop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system(\"wget https://raw.githubusercontent.com/AmeerHamza0220/covid19/main/analysis/dailyStats.csv\")"
      ],
      "metadata": {
        "id": "BD2Uk7Hei5Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(getwd())\n",
        "data=read.csv(\"dailyStats.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "G-J5z89BkenH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names(data)"
      ],
      "metadata": {
        "id": "glZ3nFu7k_Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datetime"
      ],
      "metadata": {
        "id": "FiDqj-R5l-fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['datetime']=as.numeric(as.POSIXct(datetime))"
      ],
      "metadata": {
        "id": "AwLBcENQly5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attach (data)\n",
        "fit =lm(new_cases~datetime )"
      ],
      "metadata": {
        "id": "jjXjQubwlFmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(fit)"
      ],
      "metadata": {
        "id": "6MlQ9-XOmalX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(datetime,new_cases)\n",
        "abline(fit)"
      ],
      "metadata": {
        "id": "867F78VpmM6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confint(fit)"
      ],
      "metadata": {
        "id": "71RyCMsBrNr_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}