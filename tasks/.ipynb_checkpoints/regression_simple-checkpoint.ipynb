{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7ecdac-7c56-4b43-9951-d73d71f91cb4",
   "metadata": {},
   "source": [
    "Dataset used: tabular-playground-series-aug-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11a12c70-bb78-4b59-b18f-df8f0e44f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "676b474a-489a-42a1-8462-bd3935b99f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.002350</td>\n",
       "      <td>59</td>\n",
       "      <td>0.766739</td>\n",
       "      <td>-1.350460</td>\n",
       "      <td>42.2727</td>\n",
       "      <td>16.68570</td>\n",
       "      <td>30.3599</td>\n",
       "      <td>1.267300</td>\n",
       "      <td>0.392007</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.43990</td>\n",
       "      <td>26.854000</td>\n",
       "      <td>1.45751</td>\n",
       "      <td>0.696161</td>\n",
       "      <td>0.941764</td>\n",
       "      <td>1.828470</td>\n",
       "      <td>0.924090</td>\n",
       "      <td>2.29658</td>\n",
       "      <td>10.48980</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.784462</td>\n",
       "      <td>145</td>\n",
       "      <td>-0.463845</td>\n",
       "      <td>-0.530421</td>\n",
       "      <td>27324.9000</td>\n",
       "      <td>3.47545</td>\n",
       "      <td>160.4980</td>\n",
       "      <td>0.828007</td>\n",
       "      <td>3.735860</td>\n",
       "      <td>...</td>\n",
       "      <td>-184.13200</td>\n",
       "      <td>7.901370</td>\n",
       "      <td>1.70644</td>\n",
       "      <td>-0.494699</td>\n",
       "      <td>-2.058300</td>\n",
       "      <td>0.819184</td>\n",
       "      <td>0.439152</td>\n",
       "      <td>2.36470</td>\n",
       "      <td>1.14383</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.317816</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.432571</td>\n",
       "      <td>-0.382644</td>\n",
       "      <td>1383.2600</td>\n",
       "      <td>19.71290</td>\n",
       "      <td>31.1026</td>\n",
       "      <td>-0.515354</td>\n",
       "      <td>34.430800</td>\n",
       "      <td>...</td>\n",
       "      <td>7.43721</td>\n",
       "      <td>37.218100</td>\n",
       "      <td>3.25339</td>\n",
       "      <td>0.337934</td>\n",
       "      <td>0.615037</td>\n",
       "      <td>2.216760</td>\n",
       "      <td>0.745268</td>\n",
       "      <td>1.69679</td>\n",
       "      <td>12.30550</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.210753</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.616454</td>\n",
       "      <td>0.946362</td>\n",
       "      <td>-119.2530</td>\n",
       "      <td>4.08235</td>\n",
       "      <td>185.2570</td>\n",
       "      <td>1.383310</td>\n",
       "      <td>-47.521400</td>\n",
       "      <td>...</td>\n",
       "      <td>9.66778</td>\n",
       "      <td>0.626942</td>\n",
       "      <td>1.49425</td>\n",
       "      <td>0.517513</td>\n",
       "      <td>-10.222100</td>\n",
       "      <td>2.627310</td>\n",
       "      <td>0.617270</td>\n",
       "      <td>1.45645</td>\n",
       "      <td>10.02880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.439671</td>\n",
       "      <td>20</td>\n",
       "      <td>0.968126</td>\n",
       "      <td>-0.092546</td>\n",
       "      <td>74.3020</td>\n",
       "      <td>12.30650</td>\n",
       "      <td>72.1860</td>\n",
       "      <td>-0.233964</td>\n",
       "      <td>24.399100</td>\n",
       "      <td>...</td>\n",
       "      <td>290.65700</td>\n",
       "      <td>15.604300</td>\n",
       "      <td>1.73557</td>\n",
       "      <td>-0.476668</td>\n",
       "      <td>1.390190</td>\n",
       "      <td>2.195740</td>\n",
       "      <td>0.826987</td>\n",
       "      <td>1.78485</td>\n",
       "      <td>7.07197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        f0   f1        f2        f3          f4        f5        f6  \\\n",
       "0   0 -0.002350   59  0.766739 -1.350460     42.2727  16.68570   30.3599   \n",
       "1   1  0.784462  145 -0.463845 -0.530421  27324.9000   3.47545  160.4980   \n",
       "2   2  0.317816   19 -0.432571 -0.382644   1383.2600  19.71290   31.1026   \n",
       "3   3  0.210753   17 -0.616454  0.946362   -119.2530   4.08235  185.2570   \n",
       "4   4  0.439671   20  0.968126 -0.092546     74.3020  12.30650   72.1860   \n",
       "\n",
       "         f7         f8  ...        f91        f92      f93       f94  \\\n",
       "0  1.267300   0.392007  ...  -42.43990  26.854000  1.45751  0.696161   \n",
       "1  0.828007   3.735860  ... -184.13200   7.901370  1.70644 -0.494699   \n",
       "2 -0.515354  34.430800  ...    7.43721  37.218100  3.25339  0.337934   \n",
       "3  1.383310 -47.521400  ...    9.66778   0.626942  1.49425  0.517513   \n",
       "4 -0.233964  24.399100  ...  290.65700  15.604300  1.73557 -0.476668   \n",
       "\n",
       "         f95       f96       f97      f98       f99  loss  \n",
       "0   0.941764  1.828470  0.924090  2.29658  10.48980    15  \n",
       "1  -2.058300  0.819184  0.439152  2.36470   1.14383     3  \n",
       "2   0.615037  2.216760  0.745268  1.69679  12.30550     6  \n",
       "3 -10.222100  2.627310  0.617270  1.45645  10.02880     2  \n",
       "4   1.390190  2.195740  0.826987  1.78485   7.07197     1  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_csv('data/train.csv')\n",
    "test_data=pd.read_csv('data/test.csv')\n",
    "# predict loss based on the features \n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8130f161-8a47-47e1-b143-e0d6e30f8b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>124999.500000</td>\n",
       "      <td>0.511213</td>\n",
       "      <td>51.378476</td>\n",
       "      <td>0.107155</td>\n",
       "      <td>0.050010</td>\n",
       "      <td>3595.133426</td>\n",
       "      <td>8.205953</td>\n",
       "      <td>164.508753</td>\n",
       "      <td>0.375533</td>\n",
       "      <td>16.669745</td>\n",
       "      <td>...</td>\n",
       "      <td>4856.812768</td>\n",
       "      <td>22.579100</td>\n",
       "      <td>2.030554</td>\n",
       "      <td>0.079692</td>\n",
       "      <td>1.555097</td>\n",
       "      <td>2.417556</td>\n",
       "      <td>0.537484</td>\n",
       "      <td>1.576900</td>\n",
       "      <td>8.048805</td>\n",
       "      <td>6.813920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>72168.927986</td>\n",
       "      <td>0.307884</td>\n",
       "      <td>42.396636</td>\n",
       "      <td>1.322200</td>\n",
       "      <td>0.792368</td>\n",
       "      <td>6072.401061</td>\n",
       "      <td>5.475723</td>\n",
       "      <td>183.335563</td>\n",
       "      <td>0.813597</td>\n",
       "      <td>99.758709</td>\n",
       "      <td>...</td>\n",
       "      <td>8501.609009</td>\n",
       "      <td>14.849390</td>\n",
       "      <td>0.900211</td>\n",
       "      <td>0.587780</td>\n",
       "      <td>9.253785</td>\n",
       "      <td>0.892563</td>\n",
       "      <td>0.226589</td>\n",
       "      <td>0.646306</td>\n",
       "      <td>5.647368</td>\n",
       "      <td>7.940179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.069273</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>-7.895580</td>\n",
       "      <td>-1.475560</td>\n",
       "      <td>-7589.280000</td>\n",
       "      <td>-3.291050</td>\n",
       "      <td>-40.967200</td>\n",
       "      <td>-4.143080</td>\n",
       "      <td>-502.813000</td>\n",
       "      <td>...</td>\n",
       "      <td>-12695.700000</td>\n",
       "      <td>-4.059170</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>-1.998800</td>\n",
       "      <td>-24.686300</td>\n",
       "      <td>-1.131980</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>-0.646967</td>\n",
       "      <td>-0.842397</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>62499.750000</td>\n",
       "      <td>0.251287</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-0.611172</td>\n",
       "      <td>-0.719418</td>\n",
       "      <td>163.864750</td>\n",
       "      <td>4.110127</td>\n",
       "      <td>27.894900</td>\n",
       "      <td>-0.026245</td>\n",
       "      <td>-17.392025</td>\n",
       "      <td>...</td>\n",
       "      <td>73.203100</td>\n",
       "      <td>11.525450</td>\n",
       "      <td>1.471650</td>\n",
       "      <td>-0.408975</td>\n",
       "      <td>-4.004925</td>\n",
       "      <td>1.906718</td>\n",
       "      <td>0.359646</td>\n",
       "      <td>1.215810</td>\n",
       "      <td>3.732800</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>124999.500000</td>\n",
       "      <td>0.514962</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.253815</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>943.000500</td>\n",
       "      <td>7.472445</td>\n",
       "      <td>91.005250</td>\n",
       "      <td>0.619862</td>\n",
       "      <td>8.714945</td>\n",
       "      <td>...</td>\n",
       "      <td>1060.025000</td>\n",
       "      <td>19.993200</td>\n",
       "      <td>1.660830</td>\n",
       "      <td>0.215710</td>\n",
       "      <td>0.759942</td>\n",
       "      <td>2.340430</td>\n",
       "      <td>0.531348</td>\n",
       "      <td>1.451285</td>\n",
       "      <td>7.182205</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>187499.250000</td>\n",
       "      <td>0.777322</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.759249</td>\n",
       "      <td>0.765456</td>\n",
       "      <td>4115.355000</td>\n",
       "      <td>11.030950</td>\n",
       "      <td>240.843750</td>\n",
       "      <td>0.933855</td>\n",
       "      <td>55.407625</td>\n",
       "      <td>...</td>\n",
       "      <td>5572.982500</td>\n",
       "      <td>32.271625</td>\n",
       "      <td>2.320085</td>\n",
       "      <td>0.503134</td>\n",
       "      <td>6.202503</td>\n",
       "      <td>2.910020</td>\n",
       "      <td>0.709807</td>\n",
       "      <td>1.901632</td>\n",
       "      <td>10.998550</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>249999.000000</td>\n",
       "      <td>1.072070</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>9.768590</td>\n",
       "      <td>1.680190</td>\n",
       "      <td>37847.500000</td>\n",
       "      <td>35.078000</td>\n",
       "      <td>947.143000</td>\n",
       "      <td>4.010380</td>\n",
       "      <td>465.956000</td>\n",
       "      <td>...</td>\n",
       "      <td>54334.600000</td>\n",
       "      <td>79.912400</td>\n",
       "      <td>5.403020</td>\n",
       "      <td>1.944190</td>\n",
       "      <td>42.890400</td>\n",
       "      <td>5.576040</td>\n",
       "      <td>1.105400</td>\n",
       "      <td>4.492620</td>\n",
       "      <td>34.019200</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id             f0             f1             f2  \\\n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean   124999.500000       0.511213      51.378476       0.107155   \n",
       "std     72168.927986       0.307884      42.396636       1.322200   \n",
       "min         0.000000      -0.069273     -17.000000      -7.895580   \n",
       "25%     62499.750000       0.251287      18.000000      -0.611172   \n",
       "50%    124999.500000       0.514962      41.000000       0.253815   \n",
       "75%    187499.250000       0.777322      75.000000       0.759249   \n",
       "max    249999.000000       1.072070     273.000000       9.768590   \n",
       "\n",
       "                  f3             f4             f5             f6  \\\n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean        0.050010    3595.133426       8.205953     164.508753   \n",
       "std         0.792368    6072.401061       5.475723     183.335563   \n",
       "min        -1.475560   -7589.280000      -3.291050     -40.967200   \n",
       "25%        -0.719418     163.864750       4.110127      27.894900   \n",
       "50%         0.004099     943.000500       7.472445      91.005250   \n",
       "75%         0.765456    4115.355000      11.030950     240.843750   \n",
       "max         1.680190   37847.500000      35.078000     947.143000   \n",
       "\n",
       "                  f7             f8  ...            f91            f92  \\\n",
       "count  250000.000000  250000.000000  ...  250000.000000  250000.000000   \n",
       "mean        0.375533      16.669745  ...    4856.812768      22.579100   \n",
       "std         0.813597      99.758709  ...    8501.609009      14.849390   \n",
       "min        -4.143080    -502.813000  ...  -12695.700000      -4.059170   \n",
       "25%        -0.026245     -17.392025  ...      73.203100      11.525450   \n",
       "50%         0.619862       8.714945  ...    1060.025000      19.993200   \n",
       "75%         0.933855      55.407625  ...    5572.982500      32.271625   \n",
       "max         4.010380     465.956000  ...   54334.600000      79.912400   \n",
       "\n",
       "                 f93            f94            f95            f96  \\\n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean        2.030554       0.079692       1.555097       2.417556   \n",
       "std         0.900211       0.587780       9.253785       0.892563   \n",
       "min         0.057800      -1.998800     -24.686300      -1.131980   \n",
       "25%         1.471650      -0.408975      -4.004925       1.906718   \n",
       "50%         1.660830       0.215710       0.759942       2.340430   \n",
       "75%         2.320085       0.503134       6.202503       2.910020   \n",
       "max         5.403020       1.944190      42.890400       5.576040   \n",
       "\n",
       "                 f97            f98            f99           loss  \n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000  \n",
       "mean        0.537484       1.576900       8.048805       6.813920  \n",
       "std         0.226589       0.646306       5.647368       7.940179  \n",
       "min         0.005249      -0.646967      -0.842397       0.000000  \n",
       "25%         0.359646       1.215810       3.732800       1.000000  \n",
       "50%         0.531348       1.451285       7.182205       4.000000  \n",
       "75%         0.709807       1.901632      10.998550      10.000000  \n",
       "max         1.105400       4.492620      34.019200      42.000000  \n",
       "\n",
       "[8 rows x 102 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f14e797d-6390-490f-8c08-478684c50686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f0      float64\n",
       "f1        int64\n",
       "f2      float64\n",
       "f3      float64\n",
       "f4      float64\n",
       "         ...   \n",
       "f96     float64\n",
       "f97     float64\n",
       "f98     float64\n",
       "f99     float64\n",
       "loss      int64\n",
       "Length: 101, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a72dbd37-b98d-424c-a33e-8e71df8b36a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "\n",
    "train_data.drop(['id'],axis=1,inplace=True)\n",
    "test_data.drop(['id'],axis=1,inplace=True)\n",
    "\n",
    "X=train_data.drop(['loss'],axis=1)\n",
    "y=train_data['loss']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "# scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "test_data=scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8e7eda1-6486-48ee-9bdf-0db1b9bc4198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.916118643093252\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred=regressor.predict(X_test)\n",
    "\n",
    "# RMSE\n",
    "rmse=mean_squared_error(y_test,y_pred)\n",
    "rmse=rmse**0.5\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d19c1bd4-d076-4bb5-91ee-ec13b3c41235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prediction on test data\n",
    "# y_pred=regressor.predict(test_data)\n",
    "# y_pred=y_pred.astype(int)\n",
    "# submission=pd.DataFrame({'id':test_data['id'],'loss':y_pred})\n",
    "# submission.to_csv('submission.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "edcc7c79-b155-4326-aa4f-f87685fd98da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.9154802039924155\n"
     ]
    }
   ],
   "source": [
    "# poisson regression\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "regressor=PoissonRegressor()\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred=regressor.predict(X_test)\n",
    "rmse=mean_squared_error(y_test,y_pred)\n",
    "rmse=rmse**0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54acf1a5-cd94-4e28-8276-5bacf2c3375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.899884809286778\n"
     ]
    }
   ],
   "source": [
    "# lightgbm regressor\n",
    "from lightgbm import LGBMRegressor\n",
    "params={'learning_rate':0.01,'n_estimators':1000,'max_depth':5,'min_child_weight':200,'subsample':0.8,'reg_alpha':0,'reg_lambda':0.5,'objective':'poisson','metric':'rmse', 'n_jobs':-1}\n",
    "regressor=LGBMRegressor()\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred=regressor.predict(X_test)\n",
    "y_pred=y_pred.astype(int)\n",
    "rmse=mean_squared_error(y_test,y_pred)\n",
    "rmse=rmse**0.5\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3311f9c-fc03-477e-a911-8bca27f14cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=regressor.predict(test_data)\n",
    "submission=pd.read_csv('data/sample_submission.csv')\n",
    "submission['loss']=y_pred\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f8ec3-9966-4e80-8bd4-d6188c205bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-12 02:40:30,661]\u001b[0m A new study created in memory with name: no-name-c70b626d-273b-4682-85de-fddddbdb525c\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:40:39,450]\u001b[0m Trial 0 finished with value: 7.901521372495299 and parameters: {'learning_rate': 0.027941450119790545, 'n_estimators': 658, 'max_depth': 9, 'subsample': 0.3649017837589784, 'l2_leaf_reg': 0.8668686150592857}. Best is trial 0 with value: 7.901521372495299.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:41:27,391]\u001b[0m Trial 1 finished with value: 7.94764493419277 and parameters: {'learning_rate': 0.05570824753801288, 'n_estimators': 2710, 'max_depth': 10, 'subsample': 0.7690590191703718, 'l2_leaf_reg': 0.22074215081195137}. Best is trial 0 with value: 7.901521372495299.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:41:42,382]\u001b[0m Trial 2 finished with value: 7.949169767969483 and parameters: {'learning_rate': 0.0013051866906037388, 'n_estimators': 1301, 'max_depth': 9, 'subsample': 0.5274787752566336, 'l2_leaf_reg': 0.5268406382330506}. Best is trial 0 with value: 7.901521372495299.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:41:45,588]\u001b[0m Trial 3 finished with value: 7.938634643312413 and parameters: {'learning_rate': 0.00774043090335503, 'n_estimators': 453, 'max_depth': 6, 'subsample': 0.4160711003799351, 'l2_leaf_reg': 0.3843039542380854}. Best is trial 0 with value: 7.901521372495299.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:42:02,046]\u001b[0m Trial 4 finished with value: 7.894942685035782 and parameters: {'learning_rate': 0.010477885100709041, 'n_estimators': 2013, 'max_depth': 8, 'subsample': 0.6334578532904709, 'l2_leaf_reg': 0.5414954102461174}. Best is trial 4 with value: 7.894942685035782.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:42:04,667]\u001b[0m Trial 5 finished with value: 7.89749960430515 and parameters: {'learning_rate': 0.09067221623724817, 'n_estimators': 429, 'max_depth': 4, 'subsample': 0.38405662479389857, 'l2_leaf_reg': 0.3375353341000452}. Best is trial 4 with value: 7.894942685035782.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:42:19,036]\u001b[0m Trial 6 finished with value: 7.890292770233561 and parameters: {'learning_rate': 0.03957171312127908, 'n_estimators': 1871, 'max_depth': 8, 'subsample': 0.4046596412446579, 'l2_leaf_reg': 0.7127754812054828}. Best is trial 6 with value: 7.890292770233561.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:42:24,854]\u001b[0m Trial 7 finished with value: 7.909213614513139 and parameters: {'learning_rate': 0.012528861876061462, 'n_estimators': 740, 'max_depth': 7, 'subsample': 0.8060422830583827, 'l2_leaf_reg': 0.6402447075482708}. Best is trial 6 with value: 7.890292770233561.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:42:37,844]\u001b[0m Trial 8 finished with value: 7.896301665969962 and parameters: {'learning_rate': 0.01602766707280556, 'n_estimators': 1105, 'max_depth': 9, 'subsample': 0.563630588415124, 'l2_leaf_reg': 0.6286659820409367}. Best is trial 6 with value: 7.890292770233561.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:42:52,447]\u001b[0m Trial 9 finished with value: 7.888555000759011 and parameters: {'learning_rate': 0.01169203901659235, 'n_estimators': 2771, 'max_depth': 6, 'subsample': 0.8097834738489533, 'l2_leaf_reg': 0.6526447549945165}. Best is trial 9 with value: 7.888555000759011.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:43:04,111]\u001b[0m Trial 10 finished with value: 7.925819831411764 and parameters: {'learning_rate': 0.0035467645935247966, 'n_estimators': 2921, 'max_depth': 3, 'subsample': 0.9971082004987899, 'l2_leaf_reg': 0.005294630110617704}. Best is trial 9 with value: 7.888555000759011.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:43:15,607]\u001b[0m Trial 11 finished with value: 7.882568109442506 and parameters: {'learning_rate': 0.03399905460567396, 'n_estimators': 2081, 'max_depth': 6, 'subsample': 0.7834253367981683, 'l2_leaf_reg': 0.8645261209181144}. Best is trial 11 with value: 7.882568109442506.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:43:26,784]\u001b[0m Trial 12 finished with value: 7.9146193844050385 and parameters: {'learning_rate': 0.004463827067068382, 'n_estimators': 2277, 'max_depth': 5, 'subsample': 0.8530145681599125, 'l2_leaf_reg': 0.9599611676022604}. Best is trial 11 with value: 7.882568109442506.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:43:40,727]\u001b[0m Trial 13 finished with value: 7.882485648575582 and parameters: {'learning_rate': 0.019745973291246454, 'n_estimators': 2467, 'max_depth': 6, 'subsample': 0.9155284415682092, 'l2_leaf_reg': 0.8160891907474955}. Best is trial 13 with value: 7.882485648575582.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:43:52,303]\u001b[0m Trial 14 finished with value: 7.883265820711617 and parameters: {'learning_rate': 0.02505947347517999, 'n_estimators': 2356, 'max_depth': 5, 'subsample': 0.9546696429546069, 'l2_leaf_reg': 0.8084863450296496}. Best is trial 13 with value: 7.882485648575582.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:44:03,378]\u001b[0m Trial 15 finished with value: 7.895117478543305 and parameters: {'learning_rate': 0.08065279154676083, 'n_estimators': 1691, 'max_depth': 7, 'subsample': 0.7203168919676057, 'l2_leaf_reg': 0.9594721670388948}. Best is trial 13 with value: 7.882485648575582.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:44:14,807]\u001b[0m Trial 16 finished with value: 7.884465739668097 and parameters: {'learning_rate': 0.022441604540181098, 'n_estimators': 2366, 'max_depth': 5, 'subsample': 0.8946262654934122, 'l2_leaf_reg': 0.8077718289401655}. Best is trial 13 with value: 7.882485648575582.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:44:21,722]\u001b[0m Trial 17 finished with value: 7.884933734661312 and parameters: {'learning_rate': 0.044175056227354764, 'n_estimators': 1996, 'max_depth': 3, 'subsample': 0.7020737452221417, 'l2_leaf_reg': 0.9800420324375663}. Best is trial 13 with value: 7.882485648575582.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:44:30,569]\u001b[0m Trial 18 finished with value: 7.9148278566245525 and parameters: {'learning_rate': 0.005472779932675357, 'n_estimators': 1442, 'max_depth': 6, 'subsample': 0.9119973817526585, 'l2_leaf_reg': 0.7573608672246652}. Best is trial 13 with value: 7.882485648575582.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:44:39,895]\u001b[0m Trial 19 finished with value: 7.929633030601101 and parameters: {'learning_rate': 0.002635925059635282, 'n_estimators': 2527, 'max_depth': 4, 'subsample': 0.6492042312327178, 'l2_leaf_reg': 0.8922975853781645}. Best is trial 13 with value: 7.882485648575582.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:44:54,499]\u001b[0m Trial 20 finished with value: 7.88712114779531 and parameters: {'learning_rate': 0.016575583574940187, 'n_estimators': 2136, 'max_depth': 7, 'subsample': 0.8760602253152581, 'l2_leaf_reg': 0.4398555233291828}. Best is trial 13 with value: 7.882485648575582.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:45:07,222]\u001b[0m Trial 21 finished with value: 7.880288065800641 and parameters: {'learning_rate': 0.027916507759755203, 'n_estimators': 2553, 'max_depth': 5, 'subsample': 0.9604390605660016, 'l2_leaf_reg': 0.817075813800622}. Best is trial 21 with value: 7.880288065800641.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:45:19,311]\u001b[0m Trial 22 finished with value: 7.88144022371546 and parameters: {'learning_rate': 0.033088913152451535, 'n_estimators': 2620, 'max_depth': 4, 'subsample': 0.962059562949162, 'l2_leaf_reg': 0.8689507974340671}. Best is trial 21 with value: 7.880288065800641.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:45:33,149]\u001b[0m Trial 23 finished with value: 7.884436568328773 and parameters: {'learning_rate': 0.020343921571696146, 'n_estimators': 2599, 'max_depth': 4, 'subsample': 0.9988837386283204, 'l2_leaf_reg': 0.7223481081183526}. Best is trial 21 with value: 7.880288065800641.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:45:47,951]\u001b[0m Trial 24 finished with value: 7.886097894396189 and parameters: {'learning_rate': 0.059723393278937116, 'n_estimators': 2936, 'max_depth': 5, 'subsample': 0.9339829465305001, 'l2_leaf_reg': 0.7962498766484338}. Best is trial 21 with value: 7.880288065800641.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:46:01,808]\u001b[0m Trial 25 finished with value: 7.898798642831705 and parameters: {'learning_rate': 0.007643948565138954, 'n_estimators': 2996, 'max_depth': 4, 'subsample': 0.9515130817695214, 'l2_leaf_reg': 0.8985823157882158}. Best is trial 21 with value: 7.880288065800641.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:46:11,363]\u001b[0m Trial 26 finished with value: 7.8756726696835235 and parameters: {'learning_rate': 0.058753506049257304, 'n_estimators': 2491, 'max_depth': 3, 'subsample': 0.8509558430591847, 'l2_leaf_reg': 0.6282634625357024}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:46:21,395]\u001b[0m Trial 27 finished with value: 7.8788857080173464 and parameters: {'learning_rate': 0.05248690875554154, 'n_estimators': 2729, 'max_depth': 3, 'subsample': 0.844828810118643, 'l2_leaf_reg': 0.6267414606231075}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:46:29,226]\u001b[0m Trial 28 finished with value: 7.884156264306283 and parameters: {'learning_rate': 0.060517953632607105, 'n_estimators': 1737, 'max_depth': 3, 'subsample': 0.8446792609361069, 'l2_leaf_reg': 0.579632844948699}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:46:37,396]\u001b[0m Trial 29 finished with value: 7.881503663641856 and parameters: {'learning_rate': 0.0726256119266394, 'n_estimators': 2226, 'max_depth': 3, 'subsample': 0.7378352606441306, 'l2_leaf_reg': 0.44328007265035163}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:46:47,243]\u001b[0m Trial 30 finished with value: 7.880719510298536 and parameters: {'learning_rate': 0.04130053366593596, 'n_estimators': 2838, 'max_depth': 3, 'subsample': 0.839470652319165, 'l2_leaf_reg': 0.6854174288793421}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:46:57,504]\u001b[0m Trial 31 finished with value: 7.881403428324171 and parameters: {'learning_rate': 0.04447074289048715, 'n_estimators': 2792, 'max_depth': 3, 'subsample': 0.8617306260186585, 'l2_leaf_reg': 0.6941982424989195}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:47:07,077]\u001b[0m Trial 32 finished with value: 7.882105048779799 and parameters: {'learning_rate': 0.05039654484296678, 'n_estimators': 2765, 'max_depth': 3, 'subsample': 0.8253740548939257, 'l2_leaf_reg': 0.5869158075451996}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:47:18,906]\u001b[0m Trial 33 finished with value: 7.883160533694592 and parameters: {'learning_rate': 0.028455210865417413, 'n_estimators': 2520, 'max_depth': 4, 'subsample': 0.7816203417045448, 'l2_leaf_reg': 0.5110658351617143}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:47:28,191]\u001b[0m Trial 34 finished with value: 7.877870270574402 and parameters: {'learning_rate': 0.06808003595097833, 'n_estimators': 2711, 'max_depth': 3, 'subsample': 0.7540035336158446, 'l2_leaf_reg': 0.23337375396071758}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:47:37,999]\u001b[0m Trial 35 finished with value: 7.8821659459821065 and parameters: {'learning_rate': 0.09913699701806053, 'n_estimators': 2626, 'max_depth': 4, 'subsample': 0.6907138401340502, 'l2_leaf_reg': 0.20675625639087092}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:47:39,971]\u001b[0m Trial 36 finished with value: 7.920191916866661 and parameters: {'learning_rate': 0.06818811652715304, 'n_estimators': 127, 'max_depth': 5, 'subsample': 0.5950347931071523, 'l2_leaf_reg': 0.20497326567818494}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:47:48,192]\u001b[0m Trial 37 finished with value: 7.889852977083921 and parameters: {'learning_rate': 0.030699494898821518, 'n_estimators': 2392, 'max_depth': 3, 'subsample': 0.7495480502897135, 'l2_leaf_reg': 0.06641386175004982}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:48:40,127]\u001b[0m Trial 38 finished with value: 7.930587620094743 and parameters: {'learning_rate': 0.001278070951070264, 'n_estimators': 2665, 'max_depth': 10, 'subsample': 0.4596382403136753, 'l2_leaf_reg': 0.29917990592167276}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n",
      "\u001b[32m[I 2022-07-12 02:48:44,454]\u001b[0m Trial 39 finished with value: 7.889711021323912 and parameters: {'learning_rate': 0.05556879851962521, 'n_estimators': 944, 'max_depth': 4, 'subsample': 0.7640489558532905, 'l2_leaf_reg': 0.45973075830984556}. Best is trial 26 with value: 7.8756726696835235.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "# catboost regressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "def objective(trial):\n",
    "    params={'learning_rate':trial.suggest_loguniform('learning_rate',0.001,0.1),'n_estimators':trial.suggest_int('n_estimators',100,3000),'max_depth':trial.suggest_int('max_depth',3,10),'subsample':trial.suggest_uniform('subsample',0.3,1),'l2_leaf_reg':trial.suggest_uniform('l2_leaf_reg',0,1),'objective':'RMSE', 'bootstrap_type':'Poisson',\n",
    "      'task_type':'GPU'}\n",
    "    regressor=CatBoostRegressor(**params)\n",
    "\n",
    "    regressor.fit(X_train,y_train,verbose=0)\n",
    "    y_pred=regressor.predict(X_test)\n",
    "    y_pred=y_pred.astype(int)\n",
    "    rmse=mean_squared_error(y_test,y_pred)\n",
    "    rmse=rmse**0.5\n",
    "    return rmse\n",
    "study=optuna.create_study(direction='minimize')\n",
    "study.optimize(objective,n_trials=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae5ec1-ab2f-4560-9ac1-a50fe6a3cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.best_params\n",
    "params['task_type']='GPU'\n",
    "params['bootstrap_type']='Poisson'\n",
    "regressor=CatBoostRegressor(**params)\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred=regressor.predict(X_test)\n",
    "y_pred=y_pred.astype(int)\n",
    "rmse=mean_squared_error(y_test,y_pred)\n",
    "rmse=rmse**0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c336280c-6a23-4d78-a688-9e663b9982a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat:Python",
   "language": "python",
   "name": "conda-env-stat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
