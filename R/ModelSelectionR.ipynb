{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled38.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN/NeRVLRazIJW1b7NIHWvq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmeerHamza0220/MachineLearningBasic/blob/main/ModelSelectionR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By removing extra features our model becomes more interpretable.\n",
        "We will see.\n",
        "We will see following approach for feature selection\n",
        "<li>Subset selection</li>\n",
        "We try all combination of subset and select best\n",
        "<li>Shrinkage</li>\n",
        "Ridge regression and lasso are examples\n",
        "<li>Dimention reduction</li>\n",
        "Linear combination and projection\n",
        "\n",
        "<b>Subset selection</b>\n",
        "\n",
        "First we create null model $M_0$\n",
        "Then \n",
        "For k from 1 to p:\n",
        " Fit all ${p\\choose k}$ choose k model select best save it to $M_k$\n",
        "\n",
        "Finally we need to select the best model from  $M_0$ to $M_k$. There are many ways to do that.\n",
        "NOTE: Subset selection cannot ne applied when p is large because there are $2^p$ total possible predictors. And it also suffer from overfitting.\n",
        "\n",
        "<b>Stepwise selection</b>\n",
        "Instead of fitting all possible predictor we fit on #p^2$.\n",
        "Start with $M_0$ \n",
        "for all k from 0 to p-1:\n",
        " select all p-k model\n",
        " select best\n",
        "\n",
        " Backward selection is opposite. Start with $M_p$ then remove predictor one at a time"
      ],
      "metadata": {
        "id": "Nlde7jKj8F_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will see some way to select best M\n",
        "\n",
        "$C_p$ choose model with smallest $C_p$\n",
        "\n",
        "AIC criteria: choose model with smallest AIC since AIC is proportional\n",
        "\n",
        "BIC similar AIC but put larger penalty for larger model\n",
        "\n",
        "Adjusted $R^2$\n",
        "Big $R^2$ tell that model fit the data well but we cannot use $R^2$ to compare model with different #predictors.\n",
        "Adjusted $R^2$ fix that by penalizing large model so number are comparable.\n",
        "\n",
        "**Cross validation** It is better then other approaches and we also don't need to estimate $σ^2$ \n",
        "\n",
        "**Shrinkage **\n",
        "\n",
        "**Ridge Regression**\n",
        "\n",
        "In ordinary least square we minimize RSS in contrast ridge regression minimize \n",
        "$RSS+λ\\sum_{j=0}^{p}β_j^p$\n",
        "\n",
        "We are penalizing the coefficient. λ is the amount of penality. We are shrinking the parameter toward 0.\n",
        "Before applying the ridge regression we standarlize the predictors by divide each feature by their standard deviation using\n",
        "$x̂_{ij}= \\frac{x_{ij}}{\\sqrt{\\frac{1}{n}\\sum_{i=1}{n}(x_{ij}-x̂_j)}}$\n",
        "\n"
      ],
      "metadata": {
        "id": "g7g0aXkjHyMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lasso**\n",
        "\n",
        "Drawback of ridge regression is that it will select all p predictors.\n",
        "In lasso minimize:\n",
        "$RSS+λ\\sum_{j=0}^{p}|β_j|$\n",
        "\n",
        "This is called L1 penality. It does subset selection. Lasso model called sparcity model.\n",
        "\n",
        "**Tuning parameter**\n",
        "\n",
        "We use cross validation for tuning λ."
      ],
      "metadata": {
        "id": "uEgTFekaTc40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2r_jf3f8FHj"
      },
      "outputs": [],
      "source": [
        "install.packages('ISLR2')\n",
        "\n",
        "library(ISLR2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "View(Hitters)\n",
        "names(Hitters)"
      ],
      "metadata": {
        "id": "51SJIo9Ah7va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(is.na(Hitters$Salary))"
      ],
      "metadata": {
        "id": "JnzbzkJWiC1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence we see that Salary is missing for 59 players. The na.omit() function removes all of the rows that have missing values in any variable."
      ],
      "metadata": {
        "id": "5BzzLMduiK2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Hitters=na.omit(Hitters)\n",
        "dim(Hitters)"
      ],
      "metadata": {
        "id": "ZYAwrlwXiKaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(is.na(Hitters$Salary))"
      ],
      "metadata": {
        "id": "CdHAeRGRiSra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "he regsubsets() function (part of the leaps library) performs best subset selection by identifying the best model that contains a given number of predictors, where best is quantified using RSS. "
      ],
      "metadata": {
        "id": "T_NoaT9Oidv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages('leaps')\n",
        "\n",
        "library(leaps)\n",
        "regfit.full=regsubsets(Salary~.,Hitters)\n",
        "summary(regfit.full)"
      ],
      "metadata": {
        "id": "ahfEMqT4idNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An asterisk indicates that a given variable is included in the corresponding model"
      ],
      "metadata": {
        "id": "9R0NgYkMjNuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#running over all predictors\n",
        "regfit.full=regsubsets(Salary~.,Hitters,nvmax=19)\n",
        "reg.summary=summary(regfit.full)\n",
        "names(reg.summary)"
      ],
      "metadata": {
        "id": "LAjysoUPjOeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The summary() function also returns R2, RSS, adjusted R2, Cp, and BIC.\n",
        "We can examine these to try to select the best overall model.\n",
        "Plotting RSS, adjusted R2, Cp, and BIC for all of the models at once will help us decide which model to select. Note the type = \"l\" option tells R to connect the plotted points with lines\n"
      ],
      "metadata": {
        "id": "cfMh4JWoj1gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "par(mfrow=c(2,2))\n",
        "plot(reg.summary$rss,xlab=\"number of var\",ylab=\"RSS\",type='l')\n",
        "plot(reg.summary$adjr2,xlab=\"number of var\",ylab=\"Adj R2\",type='l')\n"
      ],
      "metadata": {
        "id": "jXvhMFYgj2J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a similar fashion we can plot the Cp and BIC statistics, and indicate the models with the smallest statistic using which.min()"
      ],
      "metadata": {
        "id": "wSsdkNZXlPRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(reg.summary$cp,xlab=\"number of var\",ylab=\"cp\",type='l')\n",
        "which.min(reg.summary$cp)"
      ],
      "metadata": {
        "id": "mJqnlYKZlP8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The regsubsets() function has a built-in plot() command which can\n",
        "be used to display the selected variables for the best model with a given number of predictors, ranked according to the BIC, Cp, adjusted R2, or AIC. To find out more about this function, type"
      ],
      "metadata": {
        "id": "7LeTEnfeluhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(regfit.full,scale='Cp')"
      ],
      "metadata": {
        "id": "mWseQwH9lbe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above picture, the black squares are the variables that are select for the corresponding value of cp"
      ],
      "metadata": {
        "id": "TwnledQbmFea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "v3B2gdlkmTp6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}