{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled44.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMVPo3U7X9dnUR8s+961AE4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmeerHamza0220/MachineLearningBasic/blob/main/beyongLinearty.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this chapter we relax the linearty assumption and will see simple extension of linear model\n",
        "\n",
        "• Polynomial regression extends the linear model by adding extra predictors, obtained by raising each of the original predictors to a power. For example, a cubic regression uses three variables, X, X2, and X3, as predictors. This approach provides a simple way to provide a nonlinear fit to data.\n",
        "\n",
        "• Step functions cut the range of a variable into K distinct regions in order to produce a qualitative variable. This has the effect of fitting a piecewise constant function.\n",
        "\n",
        "• Regression splines are more flexible than polynomials and step functions, and in fact are an extension of the two. They involve dividing the range of X into K distinct regions. Within each region, a polynomial function is fit to the data. However, these polynomials are constrained so that they join smoothly at the region boundaries, or knots. Provided that the interval is divided into enough regions, this can produce an extremely flexible fit.\n",
        "\n",
        "• Smoothing splines are similar to regression splines, but arise in a slightly different situation. Smoothing splines result from minimizing a residual sum of squares criterion subject to a smoothness penalty.\n",
        "\n",
        "• Local regression is similar to splines, but differs in an important way. The regions are allowed to overlap, and indeed they do so in a very smooth way.\n",
        "\n",
        "• Generalized additive models allow us to extend the methods above to deal with multiple predictors."
      ],
      "metadata": {
        "id": "cOm-b8Z0TqN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial Regression had already been covered in chapter 1.\n",
        "\n",
        "**Step Functions**\n",
        "\n",
        "In greater detail, we create cutpoints c1, c2,. .., cK in the range of X, and then construct K + 1 new variables\n",
        "$C_0(X)= I(X< c_1).....$\n",
        "\n",
        "We then use least squares to fit a linear model using $C_1(X),C_2(X),. ..,C_K(X)$ as predictors.\n",
        "\n",
        "**Basis Functions**\n",
        "\n",
        "Polynomial and piecewise-constant regression models are in fact special cases of a basis function approach. The idea is to have at hand a family of functions or transformations that can be applied to a variable X: b1(X),b2(X),. .., bK(X). Instead of fitting a linear model in X, we fit the model on tranformations.\n",
        "\n",
        "**Regression Splines**\n",
        "\n",
        "**1.1 Piecewise Polynomials**\n",
        "\n",
        "Instead of fitting a high-degree polynomial over the entire range of X, piecewise polynomial regression involves fitting separate low-degree polynomials\n",
        "over different regions of X.\n",
        "the coefficients $β_0, β_1, β_2, and β_3 differ in different parts of the range of X. But the resulting function will be discontinous so we constraint the function to be continious. The location where value of parameters change called knot.\n",
        "\n",
        "**Choosing the Number and Locations of the Knots**\n",
        "\n",
        "How many knots should we use, or equivalently how many degrees of freedom should our spline contain? One option is to try out different numbers of knots and see which produces the best looking curve. A somewhat more objective approach is to use cross-validation.\n",
        "\n",
        "**Smoothing Splines**"
      ],
      "metadata": {
        "id": "w75KiAcUUECc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWkbY9g-Tg6_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}